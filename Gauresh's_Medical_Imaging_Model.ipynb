{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gauresh's-Medical-Imaging-Model.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPX7ZElh6J1CP2xL0It2fXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaureshKapoor/Medical-Imaging-CNN/blob/master/Gauresh's_Medical_Imaging_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSQYjCM2DauK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n",
        "def augment(data, augmenter):\n",
        "  if len(data.shape) == 3:\n",
        "    return augmenter.augment_image(data)\n",
        "  if len(data.shape) == 4:\n",
        "    return augmenter.augment_images(data)\n",
        "    \n",
        "def rotate(data, rotate):\n",
        "  fun = augmenters.Affine(rotate = rotate)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def shear(data, shear):\n",
        "  fun = augmenters.Affine(shear = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def scale(data, scale):\n",
        "  fun = augmenters.Affine(scale = scale)\n",
        "  return augment(data, fun)\n",
        "  \n",
        "def flip_left_right(data):\n",
        "  fun = augmenters.Fliplr(1)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_up_down(data):\n",
        "  fun = augmenters.Flipud(1)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def remove_color(data, channel):\n",
        "  new_data = data.copy()\n",
        "  if len(data.shape) == 3:\n",
        "    new_data[:,:,channel] = 0\n",
        "    return new_data\n",
        "  if len(data.shape) == 4:\n",
        "    new_data[:,:,:,channel] = 0\n",
        "    return new_data\n",
        "  \n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):  \n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of? \n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    return metadata[keep_idx]\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True \n",
        "    '''\n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "  \n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels      \n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "  #### QUERYING AND COMBINING DATA\n",
        "  def get_misclassified_data(data, labels, predictions):\n",
        "    '''\n",
        "    Gets the data and labels that are misclassified in a classification task\n",
        "    Returns:\n",
        "    -missed_data\n",
        "    -missed_labels\n",
        "    -predicted_labels (corresponding to missed_labels)\n",
        "    -missed_index (indices of items in original dataset)\n",
        "    '''\n",
        "    missed_index     = np.where(np.abs(predictions.squeeze() - labels.squeeze()) > 0)[0]\n",
        "    missed_labels    = labels[missed_index]\n",
        "    missed_data      = data[missed_index,:]\n",
        "    predicted_labels = predictions[missed_index]\n",
        "    return missed_data, missed_labels, predicted_labels, missed_index\n",
        "\n",
        "  def combine_data(data_list, labels_list):\n",
        "    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n",
        "\n",
        "  def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry. \n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 1)    \n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params, dropout = 1):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      if dropout:\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNNClassifier(num_hidden_layers, nn_params, dropout = 1):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten()) \n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Dense(units = 64, activation = 'relu'))\n",
        "\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.rmsprop(lr=1e-4, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])    \n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = False):\n",
        "    expert_dict = {'VGG16': VGG16, \n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet', \n",
        "                                              include_top = False, \n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "      \n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'], \n",
        "                  optimizer = optimizers.SGD(lr=1e-4, momentum=0.95), \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import model_selection\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications import VGG16, VGG19, ResNet50, DenseNet121\n",
        "\n",
        "from imgaug import augmenters \n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "image_data_url       = 'https://drive.google.com/uc?id=1DNEiLAWguswhiLXGyVKsgHIRm1xZggt_'\n",
        "metadata_url         = 'https://drive.google.com/uc?id=1MW3_FU6qc0qT_uG4bzxhtEHy4Jd6dCWb'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 1\n",
        "nn_params['loss']              = 'binary_crossentropy'\n",
        "nn_params['output_activation'] = 'sigmoid'\n",
        "\n",
        "###\n",
        "gdown.download(image_data_url, './image_data.npy', True)\n",
        "gdown.download(metadata_url, './metadata.csv', True)\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# querying and combining data\n",
        "model_to_string        = lambda model: helpers.model_to_string(model)\n",
        "get_misclassified_data = helpers.get_misclassified_data;\n",
        "combine_data           = helpers.combine_data;\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbbP1Z8FzX94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KNN, LOG, DT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XfLk2NYzdKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, train_labels) = get_train_data(flatten = True)\n",
        "(test_data, test_labels) = get_test_data(flatten = True)\n",
        "\n",
        "knn  = KNeighborsClassifier(n_neighbors=20)\n",
        "log  = LogisticRegression()\n",
        "dt   = DecisionTreeClassifier(max_depth =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX93ZnnjEaiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(train_data, train_labels)\n",
        "log.fit(train_data, train_labels)\n",
        "dt.fit(train_data, train_labels)\n",
        "\n",
        "print('KNN score: %0.4f'%(knn.score(test_data, test_labels)*100))\n",
        "print('Log score: %0.4f'%(log.score(test_data, test_labels)*100))\n",
        "print('DT score: %0.4f'%(dt.score(test_data, test_labels)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y2yJ0Hymeys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cz_nuUmyot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels = get_test_data()\n",
        "\n",
        "#setup the model(s)\n",
        "dense = DenseClassifier(hidden_layer_sizes = (128,64))\n",
        "cnn = CNNClassifier(num_hidden_layers = 5)\n",
        "\n",
        "# fit the model\n",
        "\n",
        "dense.fit(train_data, train_labels, epochs = 10, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "\n",
        "cnn.fit(train_data, train_labels, epochs = 25, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KehkHi9Sp7hQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Dense')\n",
        "plot_acc(dense.history)\n",
        "\n",
        "score = dense.evaluate(test_data, test_labels, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "print('CNN')\n",
        "plot_acc(cnn.history)\n",
        "\n",
        "score1 = cnn.evaluate(test_data, test_labels, verbose=0)\n",
        "print('Test loss:', score1[0])\n",
        "print('Test accuracy:', score1[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2qiS2Fd-srF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels = get_test_data()\n",
        "transfer = TransferClassifier(name = 'VGG19')\n",
        "transfer.fit(train_data, train_labels, epochs = 25, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "plot_acc(transfer.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkBo6G8f_FYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('TRANSFER VGG')\n",
        "plot_acc(transfer.history)\n",
        "\n",
        "score2 = transfer.evaluate(test_data, test_labels, verbose=0)\n",
        "print('Test loss:', score2[0])\n",
        "print('Test accuracy:', score2[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSmSBVMz_T6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dPw-PMV_X4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = transfer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R5GsWSv_aNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = best_model.predict_classes(test_data)\n",
        "confusion = confusion_matrix(test_labels, predictions)\n",
        "print(confusion)\n",
        "\n",
        "tp  = confusion[1][1]\n",
        "tn  = confusion[0][0] \n",
        "fp = confusion[0][1]\n",
        "fn = confusion[1][0]\n",
        "\n",
        "print('True positive: %d'%tp)\n",
        "print('True negative: %d'%tn)\n",
        "print('False positive: %d'%fp)\n",
        "print('False negative: %d'%fn)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(confusion, annot = True, fmt = 'd', cbar_kws={'label':'count'});\n",
        "plt.ylabel('Actual');\n",
        "plt.xlabel('Predicted');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQaQm5q_qn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "print('Accuracy is %d %%'%(accuracy_score(test_labels, predictions)*100.0))\n",
        "print('Precision is %d %%'%(precision_score(test_labels, predictions)*100.0))\n",
        "print('Recall is %d %%'%(recall_score(test_labels, predictions)*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Neomw1-AFsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels   = get_test_data()\n",
        "field_data, field_labels = get_field_data()\n",
        "  \n",
        "average_accuracy = 0.0\n",
        "for i in range(5):\n",
        "  cnn_old = best_model\n",
        "  cnn_old.fit(train_data, train_labels, epochs = 20, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "  \n",
        "  predictions = cnn_old.predict_classes(field_data)\n",
        "  accuracy = accuracy_score(field_labels, predictions)\n",
        "  print('Accuracy on this run: %0.2f' % accuracy)\n",
        "  \n",
        "  average_accuracy += accuracy / 5.0\n",
        "print('Average accuracy: ', average_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNRffO5rBo0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVbMXPmpBpQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNDERSTANDING THE PROBLEMS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZihM6UiA1ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[missed_data, missed_labels, predicted_labels, missed_indices] = get_misclassified_data(field_data, field_labels, predictions)\n",
        "\n",
        "print('How many bad images?')\n",
        "print(missed_data.shape[0])\n",
        "\n",
        "print('Which labels are bad?')\n",
        "print(missed_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2548R_gBVB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjVVyDZWBUnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AUGMENTATION OF DATA TO IMPROVE PERFORMANCE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDAJuMq6BAE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_INDEX = 0\n",
        "image = train_data[IMAGE_INDEX,:,:,:]\n",
        "plot_one_image(shear(image, shear = 10))\n",
        "plot_one_image(flip_left_right(image))\n",
        "plot_one_image(flip_up_down(image))\n",
        "plot_one_image(rotate(image, rotate = 90))\n",
        "plot_one_image(remove_color(image, channel = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBZZ31ucBJYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make red images\n",
        "red_train  = remove_color(remove_color(train_data[:1000], channel = 1), channel = 2)\n",
        "red_labels   = train_labels[:1000]\n",
        "\n",
        "# make rotated images\n",
        "rotate_train    = rotate(train_data[1000:2000], rotate = 90)\n",
        "rotate_labels   = train_labels[1000:2000]\n",
        "\n",
        "# combine data\n",
        "all_data, all_labels = combine_data([train_data, rotate_train, red_train], [train_labels, rotate_labels, red_labels])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONGkx3CWBOq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, train_labels = get_train_data()\n",
        "test_data, test_labels   = get_test_data()\n",
        "field_data, field_labels   = get_field_data()\n",
        "\n",
        "average_accuracy = 0.0\n",
        "\n",
        "for i in range(5):\n",
        "  cnn = best_model\n",
        "  cnn.fit(all_data, all_labels, epochs = 20, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "  predictions = cnn.predict_classes(field_data)\n",
        "  accuracy = accuracy_score(field_labels, predictions)\n",
        "  print('Accuracy:%0.2f'%accuracy)\n",
        "  average_accuracy += accuracy\n",
        "\n",
        "average_accuracy /= 5.0\n",
        "\n",
        "print('Average accuracy: ', average_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}